{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Python 網路爬蟲實做簡介</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "網路的世界有需多資料可以被挖掘，配合大數據技術，網路的資料提供資料處理、分析、及應用練習，甚至可以支持商業的用途。從網頁內容挖掘資料的技術稱為網路資料探勘(webmining)。web scraping是一個以Python為基礎的架構用於由網頁獲得資料以供分析應用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 網頁組成\n",
    "\n",
    "當我們要在電腦瀏覽器上讀取一個網頁時，瀏覽器先送一個要求(request)给網頁伺服器。`requests.get`使我們可以從伺服器獲得網頁檔案，伺服器接受要求後，會送回一個網頁檔案，瀏覽器可以顯示這個檔案內容。網頁檔案包含以下幾個組成：\n",
    "\n",
    "* HTML：包括網頁內容\n",
    "* CSS：網頁顯示的格式\n",
    "* JS：Javascript指令提供使用者與網頁互動能力\n",
    "* Images：允許網頁顯示圖像的格式，如JPG，PNG格式。\n",
    "\n",
    "當我們存取網頁資料進行scraping時，並不會破壞網頁，我們只是將HTML中有興趣的內容擷取出來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "HTML(HyperText Markup Language)稱為建構網頁的程式語言，但它並不像Python或Java，它是一種標記語言(Markup Language)用於定義瀏覽器如何展示內容。HTML的組成元件稱為標籤(tag)，如`<html>`標籤。以下是最基本的一個HTML程式。\n",
    "\n",
    "```html\n",
    "<html>\n",
    "</html>\n",
    "```\n",
    "\n",
    "再加入二個基本關鍵標籤，`<hea>`及`<body>`，`<head>`標籤主要定義網頁的名稱抬頭，`<body>`標籤定義網頁的內容。以下為網頁HTML程式的基本架構。\n",
    "    \n",
    "```html\n",
    "<heml>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "網頁的內容可以由許多標籤組成，其中`<p>`表示獨立的文字段落。例如以下例子顯示二段獨立的文字。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` html\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>\n",
    "            這是第一段文字!\n",
    "        </p>\n",
    "        <p>\n",
    "            這是第二段文字!\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>\n",
    "            這是第一段文字!\n",
    "        </p>\n",
    "        <p>\n",
    "            這是第二段文字!\n",
    "        </p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML程式中的標籤有二個值得注意的地方，一是位置，一是屬性。\n",
    "\n",
    "標籤的位置指與其他標籤間的關係，有以下三類\n",
    "  - child：指該標籤存在於另一個標籤中，如`p`為`body`的child。\n",
    "  - parent：指該標籤包含另一個標籤，如`html`為`body`的parent。\n",
    "  - sibiling：指標籤在同一個parent標籤之下，如`head`與`body`為sibiling，二個`p`為sibiling。\n",
    "\n",
    "在上述的HTML中加入二個新的標籤`<a>`。`<a>`是連結(link)標籤，用於連結到另一個網頁。其中，`href`是它的屬性，定義連結網頁的位址。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` html\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>\n",
    "            這是第一段文字!\n",
    "            <a href=\"http://www.cust.edu.tw\">中華科技大學</a>\n",
    "        </p>\n",
    "        <p>\n",
    "            這是第二段文字!\n",
    "            <a href=\"https://sites.google.com/view/jc7qx\">鍾健雄老師教學網頁</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>\n",
    "            這是第一段文字!\n",
    "            <a href=\"http://www.cust.edu.tw\">中華科技大學</a>\n",
    "        </p>\n",
    "        <p>\n",
    "            這是第二段文字!\n",
    "            <a href=\"https://sites.google.com/view/jc7qx\">鍾健雄老師教學網頁</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下綜整HTML程式常用的標籤：\n",
    "\n",
    "| 標籤名稱 | 標籤用途 |\n",
    "|---------|---------|\n",
    "| p    | 文字段落  |\n",
    "| a    | 定義超連結 |\n",
    "| div  | 定義網頁的部份區域 ｜\n",
    "| b    | 文字粗體 ｜\n",
    "| i    | 文字斜體 |\n",
    "| table | 定義表格 |\n",
    "| form  | 定義輸入表格 |\n",
    "\n",
    "更詳細的HTML元件請參考<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Element\">這裡</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，有關標籤還有二個重要的屬性用於scrapy應用，即`class`及`id`。這兩個標籤的屬性可定義HTML元件的名稱，可用於scrapy。請見以下範例\n",
    "\n",
    "``` html\n",
    "\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"bold-paragraph\">\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\" id=\"learn-link\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p class=\"bold-paragraph extra-large\">\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests 程式套件\n",
    "\n",
    "requests套件的`get`函式可以送出要求至網頁伺服器，下載回傳網頁HTML檔案內容。以下範例使我們下載一個簡單的HTML檔案。執行結果回傳一個狀態`200`表示執行成果，`page.status_code`顯示狀態編號，`page.content`表示執行結果內容。\n",
    "\n",
    "狀態訊號 | 說明\n",
    "--------|-----\n",
    "200     | ok回傳結果\n",
    "301     |\n",
    "401     |\n",
    "400     |\n",
    "403     |\n",
    "404     | 找不到檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "BeautifulSoup是一個用於解析HTML內容的python工具套件。首先，導入bs4套件中的BeautifulSoup函式，再來建立一個BeatifulSoup的物件`soup`，利用`html.parser`來解析HTML頁面程式。可以利用BeautifulSoup物件的`prettify()`方法來顯示HTML程式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML中所有標籤都是階層性的，`soup.children`用來選擇網頁首層(top level)的元件，產生一個串列結果，可以利用`list`函式來建立串列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html', '\\n', <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.NavigableString, bs4.element.Tag]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <head>\n",
       " <title>A simple example page</title>\n",
       " </head>, '\\n', <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>, '\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = list(soup.children)[2]\n",
    "list(html.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <p>Here is some simple content for this page.</p>, '\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(body.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Python 爬蟲實戰</h1>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(\"http://jimmy15923.github.io/example_page\")\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "print(soup.find(\"h1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests.get(...)`表示點擊網頁的URL，點擊網頁時有二種方法：GET及POST\n",
    "\n",
    "Requests的常用函數\n",
    "* response.status_code\n",
    "  - 200 ok\n",
    "  - 403 Forbidden\n",
    "  - 404 Not Found\n",
    "* response.encoding\n",
    "  - 特別要注意中文網站編碼\n",
    "* response.text\n",
    "  - 目標網頁的HTML文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n\\n<html>\\n<head>\\n\\t<meta charset=\"UTF-8\" />\\n\\t<title>網頁名稱-python crawler</title>\\n\\t<style>\\n\\t.abc {\\n\\t\\tcolor: blue;\\n\\t\\tfont-size: 40px;\\t\\n\\t}\\n\\n\\t#i-am-id {\\n\\t\\tbackground-color: LightCyan;\\n\\t}\\n\\n\\ttable, th, td {\\n\\t\\tborder: 1px solid black;\\n\\t    border-collapse: collapse;\\n\\t}\\n\\tth, td {\\n\\t\\tpadding: 10px;\\n\\t}\\n\\t</style>\\n</head>\\n<body>\\n\\t<h1>Python 爬蟲實戰</h1>\\n\\t<h2>這是 h2 標籤的內容</h2>\\n\\t<h3>這是 h3 標籤的內容</h3>\\n\\n\\t<p title=\"i-am-title\">這是 p 標籤的內容</p>\\n\\n\\t<div> \\n\\t這是 div 標籤的內容，\\n\\t即使換行寫，網頁顯示出的文字一樣是不會換行\\n\\t</div>\\n\\n\\t<p>但如果用了 br 標籤 <br/> 就可以順利斷行了</p>\\n\\t\\n\\t<div class = \"zzz\" id = \"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>\\n\\t<p hidden>python_crawler</p>\\n\\t<div id = \"value-of-attr\">\\n\\t我是有著屬性 id=\"value-of-attr\" 的標籤內容\\n\\t\\n\\t\\t<table id = \"i-am-id\">\\n\\t\\t  <tr>\\n\\t\\t\\t<th>標頭 1 (table-header)</th>\\n\\t\\t\\t<th>標頭 2 (table-header)</th>\\n\\t\\t\\t<th>標頭 3 (table-header)</th>\\n\\t\\t\\t<th>標頭 4 (table-header)</th>\\n\\t\\t  </tr>\\n\\t\\t  <tr>\\n\\t\\t\\t<td> 列2 欄1 </td>\\n\\t\\t\\t<td class = \"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>\\n\\t\\t\\t<td> \\n\\t\\t\\t\\t<a href = \"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a> \\n\\t\\t\\t</td>\\n\\t\\t\\t<td> \\n\\t\\t\\t\\t<a href = \"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>  \\n\\t\\t\\t</td>\\n\\t\\t  </tr>\\n\\t\\t  <tr>\\n\\t\\t\\t<td value = \"5566\">列3 欄1 </td>\\n\\t\\t\\t<td>列3 欄2\\n\\t\\t\\t\\t<ol>\\n\\t\\t\\t\\t\\t<li class = \"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>\\n\\t\\t\\t\\t\\t<li> 第二個 li 標籤 </li>\\n\\t\\t\\t\\t</ol>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<a href = \"http://foundation.datasci.tw/python-crawling-170813/\" id = \"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td class = \"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>\\n\\t\\t  </tr>\\n\\n\\t\\t</table>\\n\\t</div>\\n\\n\\t<p>python_crawler</p>\\n\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   網頁名稱-python crawler\n",
      "  </title>\n",
      "  <style>\n",
      "   .abc {\n",
      "\t\tcolor: blue;\n",
      "\t\tfont-size: 40px;\t\n",
      "\t}\n",
      "\n",
      "\t#i-am-id {\n",
      "\t\tbackground-color: LightCyan;\n",
      "\t}\n",
      "\n",
      "\ttable, th, td {\n",
      "\t\tborder: 1px solid black;\n",
      "\t    border-collapse: collapse;\n",
      "\t}\n",
      "\tth, td {\n",
      "\t\tpadding: 10px;\n",
      "\t}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Python 爬蟲實戰\n",
      "  </h1>\n",
      "  <h2>\n",
      "   這是 h2 標籤的內容\n",
      "  </h2>\n",
      "  <h3>\n",
      "   這是 h3 標籤的內容\n",
      "  </h3>\n",
      "  <p title=\"i-am-title\">\n",
      "   這是 p 標籤的內容\n",
      "  </p>\n",
      "  <div>\n",
      "   這是 div 標籤的內容，\n",
      "\t即使換行寫，網頁顯示出的文字一樣是不會換行\n",
      "  </div>\n",
      "  <p>\n",
      "   但如果用了 br 標籤\n",
      "   <br/>\n",
      "   就可以順利斷行了\n",
      "  </p>\n",
      "  <div class=\"zzz\" id=\"id1\">\n",
      "   我是有著屬性 class=\"zzz\" 的標籤內容\n",
      "  </div>\n",
      "  <p hidden=\"\">\n",
      "   python_crawler\n",
      "  </p>\n",
      "  <div id=\"value-of-attr\">\n",
      "   我是有著屬性 id=\"value-of-attr\" 的標籤內容\n",
      "   <table id=\"i-am-id\">\n",
      "    <tr>\n",
      "     <th>\n",
      "      標頭 1 (table-header)\n",
      "     </th>\n",
      "     <th>\n",
      "      標頭 2 (table-header)\n",
      "     </th>\n",
      "     <th>\n",
      "      標頭 3 (table-header)\n",
      "     </th>\n",
      "     <th>\n",
      "      標頭 4 (table-header)\n",
      "     </th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      列2 欄1\n",
      "     </td>\n",
      "     <td class=\"zzz\">\n",
      "      列2 欄2 (我的屬性 class=\"zzz\")\n",
      "     </td>\n",
      "     <td>\n",
      "      <a href=\"http://www.yahoo.com.tw\">\n",
      "       列2 欄3 (我是 a 標籤，屬性 href=網址)\n",
      "      </a>\n",
      "     </td>\n",
      "     <td>\n",
      "      <a href=\"http://foundation.datasci.tw/\">\n",
      "       列2 欄4 (資料協會)\n",
      "      </a>\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td value=\"5566\">\n",
      "      列3 欄1\n",
      "     </td>\n",
      "     <td>\n",
      "      列3 欄2\n",
      "      <ol>\n",
      "       <li class=\"zz\">\n",
      "        我是 li 標籤 (列表)，屬性 class=\"zz\"\n",
      "       </li>\n",
      "       <li>\n",
      "        第二個 li 標籤\n",
      "       </li>\n",
      "      </ol>\n",
      "     </td>\n",
      "     <td>\n",
      "      <a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\">\n",
      "       列3 欄3 (資料協會-python 爬蟲實戰)\n",
      "      </a>\n",
      "     </td>\n",
      "     <td class=\"zzzz\">\n",
      "      列3 欄4 (我的屬性 class=\"zzzz\")\n",
      "     </td>\n",
      "    </tr>\n",
      "   </table>\n",
      "  </div>\n",
      "  <p>\n",
      "   python_crawler\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以節點標籤搜尋資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup可以依照HTML的節點標籤篩選出所要的資料，利用`標籤.string`(or text)可以讀取標籤文字部分。bs4的`find()`及`find_all()`函式可以用來找出節點標籤。`find()`找出第一個符合條件的節點標籤，`find_all()`可以會以遞迴的方式尋找所有的子節點標籤的內容，並以串列儲存找到的標籤內容。如果想要限制 `find_all` 只找尋次一層的子節點，可以加上 `recursive=False` 關閉遞迴搜尋功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>網頁名稱-python crawler</title>\n",
      "網頁名稱-python crawler\n",
      "<p title=\"i-am-title\">這是 p 標籤的內容</p>\n",
      "這是 p 標籤的內容\n",
      "<h1>Python 爬蟲實戰</h1>\n",
      "Python 爬蟲實戰\n",
      "<div> \n",
      "\t這是 div 標籤的內容，\n",
      "\t即使換行寫，網頁顯示出的文字一樣是不會換行\n",
      "\t</div>\n",
      " \n",
      "\t這是 div 標籤的內容，\n",
      "\t即使換行寫，網頁顯示出的文字一樣是不會換行\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.string)\n",
    "print(soup.p)\n",
    "print(soup.p.string)\n",
    "print(soup.h1)\n",
    "print(soup.h1.string)\n",
    "print(soup.div)\n",
    "print(soup.div.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p title=\"i-am-title\">這是 p 標籤的內容</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\") #和soup.p一樣的結果，找出第一個標籤p的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p title=\"i-am-title\">這是 p 標籤的內容</p>,\n",
       " <p>但如果用了 br 標籤 <br/> 就可以順利斷行了</p>,\n",
       " <p hidden=\"\">python_crawler</p>,\n",
       " <p>python_crawler</p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這是 p 標籤的內容\n",
      "但如果用了 br 標籤  就可以順利斷行了\n",
      "python_crawler\n",
      "python_crawler\n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('p'): #注意此處使用text來擷取標籤文字\n",
    "    print(p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以標籤屬性搜尋資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.yahoo.com.tw\n",
      "http://www.yahoo.com.tw\n"
     ]
    }
   ],
   "source": [
    "print(soup.a['href'])\n",
    "atag=soup.find('a')\n",
    "print(atag.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\n"
     ]
    }
   ],
   "source": [
    "# 根據 id 搜尋\n",
    "print(soup.find(id=\"hyperlink\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"zzz\" id=\"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>\n",
      "<td value=\"5566\">列3 欄1 </td>\n"
     ]
    }
   ],
   "source": [
    "# 根據屬性搜尋\n",
    "print(soup.find(attrs={\"class\":\"zzz\"}))\n",
    "print(soup.find(attrs={\"value\":\"5566\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>, <a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>]\n"
     ]
    }
   ],
   "source": [
    "# 利用 repex 搜尋資料\n",
    "import re\n",
    "link = soup.find_all(href=re.compile(\"foundation\"))\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以 CSS 搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p title=\"i-am-title\">這是 p 標籤的內容</p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('p', title=\"i-am-title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<th>標頭 1 (table-header)</th>\n",
      "<th>標頭 2 (table-header)</th>\n",
      "<th>標頭 3 (table-header)</th>\n",
      "<th>標頭 4 (table-header)</th>\n"
     ]
    }
   ],
   "source": [
    "for h in soup.find_all('th'):\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "* 強大且簡單易學的 HTML 解析器\n",
    "* 將 HTML 轉變成 BeautifulSoup 物件\n",
    "* 再用 BeautifulSoup 的函數取得想要的標籤資訊\n",
    "* BeautifulSoup 可以直接找出你想要的 tags 而不需告訴他路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Python 爬蟲實戰</h1>\n",
      "<h1>Python 爬蟲實戰</h1>\n",
      "<h1>Python 爬蟲實戰</h1>\n",
      "<h1>Python 爬蟲實戰</h1>\n",
      "<h1>Python 爬蟲實戰</h1>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"h1\"))\n",
    "print(soup.h1)\n",
    "print(soup.html.h1)\n",
    "print(soup.body.h1)\n",
    "print(soup.html.body.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Python 爬蟲實戰</h1>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"h1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 爬蟲實戰\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"h1\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td> 列2 欄1 </td>\n"
     ]
    }
   ],
   "source": [
    "# 找出第一個 td 的標籤\n",
    "print(soup.find(\"td\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 列2 欄1 \n"
     ]
    }
   ],
   "source": [
    "# 找出第一個 td 的標籤並印出其文字內容\n",
    "print(soup.find(\"td\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td> 列2 欄1 </td>, <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>, <td>\n",
      "<a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n",
      "</td>, <td>\n",
      "<a href=\"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>\n",
      "</td>, <td value=\"5566\">列3 欄1 </td>, <td>列3 欄2\n",
      "\t\t\t\t<ol>\n",
      "<li class=\"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>\n",
      "<li> 第二個 li 標籤 </li>\n",
      "</ol>\n",
      "</td>, <td>\n",
      "<a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\n",
      "</td>, <td class=\"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>]\n"
     ]
    }
   ],
   "source": [
    "# 找出所有 td 的標籤\n",
    "print(soup.find_all(\"td\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"zzz\" id=\"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>, <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>]\n"
     ]
    }
   ],
   "source": [
    "# 不指定標籤,但找出所有屬性 class = \"zzz\" 的標籤\n",
    "print(soup.find_all(\"\",{\"class\":\"zzz\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n"
     ]
    }
   ],
   "source": [
    "# 找出所有 td 標籤的第三個並找出其中的 a 標籤\n",
    "print(soup.find_all(\"td\")[2].find(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python_crawler', 'python_crawler']\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(text=\"python_crawler\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'http://www.yahoo.com.tw'}\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"a\").attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.yahoo.com.tw\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"a\")[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 請計算範例網頁中,共含有幾個 \"td\" 的標籤 (tags)?\n",
    "len(soup.find_all(\"td\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是有著屬性 class=\"zzz\" 的標籤內容\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"div\", id=\"id1\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參考資料\n",
    "\n",
    "1. [Python 使用 Beautiful Soup 抓取與解析網頁資料，開發網路爬蟲教學](https://blog.gtwang.org/programming/python-beautiful-soup-module-scrape-web-pages-tutorial/)\n",
    "2. [給初學者的 Python 網頁爬蟲與資料分析 (1)](http://blog.castman.net/%E6%95%99%E5%AD%B8/2016/12/19/python-data-science-tutorial-1.html)\n",
    "3. [Python Web Scraping Tutorial using BeautifulSoup](https://www.dataquest.io/blog/web-scraping-tutorial-python/) - [Dataquest](https://www.dataquest.io/)\n",
    "4. [How To Scrape Web Pages with Beautiful Soup and Python 3](https://www.digitalocean.com/community/tutorials/how-to-scrape-web-pages-with-beautiful-soup-and-python-3)\n",
    "5. [Modern Python web scraping using (Beautiful Soup & Selenium)](https://likegeeks.com/python-web-scraping/)\n",
    "6. [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
